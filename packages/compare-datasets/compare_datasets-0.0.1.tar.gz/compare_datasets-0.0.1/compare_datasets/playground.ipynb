{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_datasets import Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": ['21-03-2022', 'soccer', 'cricket'],\n",
    "        \"b\": [\"21-03-2022\", 'soccer', \"cricket\"],\n",
    "        \"c\": [1, 2, 3],\n",
    "    }\n",
    ")\n",
    "\n",
    "df1 = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": ['21-03-2022', 'soccer', 'cricket', 'baseball'],\n",
    "        \"b\": [\"21-03-2022\", 'sucker', \"cricket\", 'man'],\n",
    "        \"c\": [4, 2, 3, 4],\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:structure:All columns are of type string\n",
      "INFO:structure:All columns are of type string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No key provided. Performing comparison without sorting.\n",
      "The number of rows in the expected and tested dataframes do not match. \n",
      "Truncating the dataframes to the same number of rows.\n",
      "Dataframes have been truncated to the same number of rows. Since no key is provided, the first 4 of both the dataframed have been taken.\n"
     ]
    }
   ],
   "source": [
    "Compare(df, df1).save_report(\"C:\\git\\compareDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:structure:All columns are of type string\n",
      "INFO:structure:All columns are of type string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No key provided. Performing comparison without sorting.\n",
      "The number of rows in the expected and tested dataframes do not match. \n",
      "Truncating the dataframes to the same number of rows.\n",
      "Dataframes have been truncated to the same number of rows. Since no key is provided, the first 4 of both the dataframed have been taken.\n"
     ]
    }
   ],
   "source": [
    "import comparedf \n",
    "from importlib import reload\n",
    "reload(comparedf)\n",
    "import comparedf\n",
    "data = comparedf.Compare(df, df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT COMPARISON: \n",
      "| Attributes    |   Expected |   Tested |   Difference |\n",
      "|---------------+------------+----------+--------------|\n",
      "| No of columns |          3 |        3 |            0 |\n",
      "| No of rows    |          4 |        3 |            1 |\n",
      " \n",
      "COLUMNS COMPARISON: \n",
      "| Expected ∩ Tested   | Expected ∪ Tested   | Expected - Tested   | Tested - Expected   |\n",
      "|---------------------+---------------------+---------------------+---------------------|\n",
      "| a                   | a                   |                     |                     |\n",
      "| b                   | b                   |                     |                     |\n",
      "| c                   | c                   |                     |                     |\n",
      " \n",
      "SCHEMA COMPARISON: \n",
      "| Column   | Expected   | Tested   |\n",
      "|----------+------------+----------|\n",
      "| a        | Utf8       | Utf8     |\n",
      "| b        | Utf8       | Utf8     |\n",
      "| c        | Int64      | Int64    |\n",
      " \n",
      "COLUMN TYPES: \n",
      "| Numeric Columns   | String Columns   |\n",
      "|-------------------+------------------|\n",
      "| c                 | a                |\n",
      "|                   | b                |\n",
      " \n",
      "COMPARISON FOR STRING COLUMNS\n",
      "-----------------------------------------\n",
      "\n",
      "OVERALL RESULT: FAILED\n",
      "\n",
      "-----------------------------------------\n",
      "TEST 1: Jaccard Similarity\n",
      "\n",
      "RESULT: FAILED\n",
      "\n",
      "| Column Name   |   Jaccard Similarity | Result   |\n",
      "|---------------+----------------------+----------|\n",
      "| a             |                 0.75 | FAILED   |\n",
      "| b             |                 0.4  | FAILED   |\n",
      "\n",
      "Jaccard Similarity is defined as the size of the intersection divided by the size of the union of the sets. J(A,B) = |A ∩ B| / |A ∪ B|.\n",
      "The Jaccard similarity between the expected and tested dataframes is not 1 for all columns. This means that the expected and tested dataframes have different values for the same column(s).\n",
      "\n",
      "-----------------------------------------\n",
      "TEST 2: Value by Value Comparison\n",
      "\n",
      "RESULT: FAILED\n",
      "\n",
      "| Column Name   |   Total Levenshtein Distance | Result   |\n",
      "|---------------+------------------------------+----------|\n",
      "| a             |                            0 | PASSED   |\n",
      "| b             |                            2 | FAILED   |\n",
      "\n",
      "The string comparisons are done using the Levenshtein distance. The Levenshtein distance is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other.\n",
      "The Levenshtein distance between the expected and tested dataframes is not 0 for all columns. This means that the expected and tested dataframes have different string values in the same column(s).\n",
      "\n",
      "\n",
      " \n",
      "COMPARISON FOR NUMERIC COLUMNS\n",
      "-----------------------------------------\n",
      "\n",
      "OVERALL RESULT: FAILED\n",
      "\n",
      "-----------------------------------------\n",
      "TEST 1: Jaccard Similarity\n",
      "\n",
      "RESULT: FAILED\n",
      "\n",
      "| Column Name   |   Jaccard Similarity | Result   |\n",
      "|---------------+----------------------+----------|\n",
      "| c             |                  0.5 | FAILED   |\n",
      "\n",
      "Jaccard Similarity is defined as the size of the intersection divided by the size of the union of the sets. J(A,B) = |A ∩ B| / |A ∪ B|.\n",
      "The Jaccard similarity between the expected and tested dataframes is not 1 for all columns. This means that the expected and tested dataframes have different values for the same column(s).\n",
      "\n",
      "-----------------------------------------\n",
      "TEST 2: Value by Value Comparison\n",
      "\n",
      "RESULT: FAILED\n",
      "\n",
      "| Column Name   |   Euclidean Distance | Result   |\n",
      "|---------------+----------------------+----------|\n",
      "| c             |                    3 | FAILED   |\n",
      "\n",
      "The string comparisons are done using the Euclidean distance. The Euclidean distance is a measure of the straight line distance between two points in a space. Given two points P and Q with coordinates (p1, p2, ..., pn) and (q1, q2, ..., qn) respectively, the Euclidean distance d between P and Q is: d(P, Q) = sqrt((q1 - p1)² + (q2 - p2)² + ... + (qn - pn)²)\n",
      "The Euclidean distance between the expected and tested dataframes is not 0 for all columns. This means that the expected and tested dataframes have different numeric values in the same column(s).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save_report(\"C:\\\\git\\\\compareDF\\\\compareDF\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare\n",
    "import string_comparisons\n",
    "import numeric_comparisons\n",
    "import structure\n",
    "from importlib import reload\n",
    "reload(prepare)\n",
    "reload(structure)\n",
    "reload(string_comparisons)\n",
    "reload(numeric_comparisons)\n",
    "import structure\n",
    "from prepare import PrepareForComparison\n",
    "from string_comparisons import StringComparisons\n",
    "from numeric_comparisons import NumericComparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PrepareForComparison(df, df1)\n",
    "sc = StringComparisons(expected=p.expected.select(p.column_list['String Columns']), tested=p.tested.select(p.column_list['String Columns']))\n",
    "sc.generate_differenced_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PrepareForComparison(df, df1)\n",
    "sc = NumericComparisons(expected=p.expected.select(p.column_list['Numeric Columns']), tested=p.tested.select(p.column_list['Numeric Columns']))\n",
    "sc.generate_differenced_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.column_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": [1, 2],\n",
    "        \"b\": [3, 4],\n",
    "        \"c\": [5, 6],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.col(\"c\").alias(pl.col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PrepareForComparison(df, df1, key=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compare_df (tested, expected, key, tolerance):\n",
    "    result = Compare(tested, expected, key, tolerance)\n",
    "    result.testCounts()\n",
    "    print(result._result)\n",
    "    # result.test_column_names()\n",
    "    # result.test_column_types()\n",
    "    print(sum(result.row_and_column_counts[\"Difference (Expected - Tested)\"]))\n",
    "\n",
    "    return result.testCounts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compare_df(df, df1, 'a', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance_functions as dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distance_functions import compute_levenshtein_distance\n",
    "compute_levenshtein_distance([\"21-03-2022\", 'sucker', \"cricket\", \"football\", \"badminton\"], ['21-03-2022', 'soccer', 'cricket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.compute_euclidean_distance([1,2,3,4],[7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
