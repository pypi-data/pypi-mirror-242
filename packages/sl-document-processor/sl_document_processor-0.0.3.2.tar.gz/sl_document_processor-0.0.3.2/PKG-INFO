Metadata-Version: 2.1
Name: sl-document-processor
Version: 0.0.3.2
Summary: Package to process documents of any format
Author: Vamsidhar Reddy
Author-email: r.vamsireddy93@gmail.com
Requires-Python: >=3.11,<3.12
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: beautifulsoup4 (>=4.12.2,<5.0.0)
Requires-Dist: boto3 (>=1.28.78,<2.0.0)
Requires-Dist: fastapi (>=0.104.1,<0.105.0)
Requires-Dist: lxml (>=4.9.3,<5.0.0)
Requires-Dist: mypy (>=1.7.0,<2.0.0)
Requires-Dist: pdfminer (>=20191125,<20191126)
Requires-Dist: pydantic (>=2.4.2,<3.0.0)
Requires-Dist: pymongo (>=4.5.0,<5.0.0)
Requires-Dist: pymupdf (>=1.23.5,<2.0.0)
Requires-Dist: pypdf (>=3.17.0,<4.0.0)
Requires-Dist: pypdf2 (>=3.0.1,<4.0.0)
Requires-Dist: python-dotenv (>=1.0.0,<2.0.0)
Requires-Dist: pyyaml (>=6.0.1,<7.0.0)
Requires-Dist: requests (>=2.31.0,<3.0.0)
Requires-Dist: selenium (>=4.14.0,<5.0.0)
Requires-Dist: supabase (>=2.0.3,<3.0.0)
Requires-Dist: tabula-py (>=2.8.2,<3.0.0)
Requires-Dist: tika (>=2.6.0,<3.0.0)
Requires-Dist: uvicorn (>=0.23.2,<0.24.0)
Description-Content-Type: text/markdown

# Data Processor

## Description


## Installation

```bash
pip install data_processor
```

## Usage

### Scraping

Write a YAML file describing the elements to be scraped along with metadata about the source. For example:

```yaml
# sample yaml configuration file for document_processor/transform

name: "quote_bot"
version: "0.1.0"
description: "A bot that fetches quotes"
author: "Your Name"
author_email: ""
license: "MIT"
source_settings:
  url: "https://quotes.toscrape.com/tag/humor/"
  elements:
      # The elements to scrape
    - name: "quotes"
      selector_type: "css"
      # parent selector for this element
      selector: "div.quote"
      # The elements to scrape
      elements:
        - name: "quote"
          selector_type: "css"
          # The selector for this element
          selector: "span.text"
          # The attribute to scrape
          attribute: "text"
        - name: "author"
          selector_type: "xpath"
          selector: "//span/small/text()"
          attribute: "text"
        # - name: "tags"
        #   selector_type: "css"
        #   selector: ".tag"
        #   attribute: "text"
scrape_settings:
  # The number of seconds to wait between each request
  request_wait_time: 1
```

Then run the following command:

```python
from data_processor.scraping import scrape

